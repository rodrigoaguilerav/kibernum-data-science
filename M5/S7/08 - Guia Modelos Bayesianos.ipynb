{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Caso Mail Spam\n",
    "\n",
    "Los modelos bayesianos, en particular el clasificador bayesiano ingenuo (Naive Bayes), son ampliamente utilizados en la detección de spam debido a varias razones:\n",
    "\n",
    "- **Eficiencia computacional**: Los modelos bayesianos son computacionalmente eficientes y pueden manejar grandes volúmenes de datos de manera eficaz, lo que los hace adecuados para aplicaciones en las que se procesan grandes cantidades de correos electrónicos.\n",
    "\n",
    "- **Tratamiento de datos textuales**: El clasificador bayesiano ingenuo es especialmente adecuado para el procesamiento de datos textuales, como los contenidos de los correos electrónicos. Puede manejar características categóricas o discretas, lo que lo hace efectivo para analizar palabras clave y patrones de texto en los correos electrónicos.\n",
    "\n",
    "- **Capacidad para modelar probabilidades condicionales**: El enfoque bayesiano permite modelar probabilidades condicionales de que un correo electrónico sea spam o no spam dadas las características observadas en el correo electrónico. Esto se alinea bien con la naturaleza de la detección de spam, que implica hacer predicciones basadas en la probabilidad de que un correo electrónico sea spam dado su contenido.\n",
    "\n",
    "- **Adaptabilidad y actualización continua**: Los modelos bayesianos pueden adaptarse y actualizarse fácilmente con nuevos datos, lo que los hace adecuados para la detección de spam en entornos dinámicos donde los patrones de spam pueden cambiar con el tiempo\n",
    "\n",
    "\n",
    "En este caso, entrenaremos un algoritmo de clasificación de correos spam a partir del dataset https://archive.ics.uci.edu/ml/datasets/spambase con el clasificador Bayesiano."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lectura de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En el archivo spambase.names vienen los nombres de las 56 columnas\n",
    "df_names = pd.read_csv('spambase.names', sep=':', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_names.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 word_freq_make\n",
       "1              word_freq_address\n",
       "2                  word_freq_all\n",
       "3                   word_freq_3d\n",
       "4                  word_freq_our\n",
       "5                 word_freq_over\n",
       "6               word_freq_remove\n",
       "7             word_freq_internet\n",
       "8                word_freq_order\n",
       "9                 word_freq_mail\n",
       "10             word_freq_receive\n",
       "11                word_freq_will\n",
       "12              word_freq_people\n",
       "13              word_freq_report\n",
       "14           word_freq_addresses\n",
       "15                word_freq_free\n",
       "16            word_freq_business\n",
       "17               word_freq_email\n",
       "18                 word_freq_you\n",
       "19              word_freq_credit\n",
       "20                word_freq_your\n",
       "21                word_freq_font\n",
       "22                 word_freq_000\n",
       "23               word_freq_money\n",
       "24                  word_freq_hp\n",
       "25                 word_freq_hpl\n",
       "26              word_freq_george\n",
       "27                 word_freq_650\n",
       "28                 word_freq_lab\n",
       "29                word_freq_labs\n",
       "30              word_freq_telnet\n",
       "31                 word_freq_857\n",
       "32                word_freq_data\n",
       "33                 word_freq_415\n",
       "34                  word_freq_85\n",
       "35          word_freq_technology\n",
       "36                word_freq_1999\n",
       "37               word_freq_parts\n",
       "38                  word_freq_pm\n",
       "39              word_freq_direct\n",
       "40                  word_freq_cs\n",
       "41             word_freq_meeting\n",
       "42            word_freq_original\n",
       "43             word_freq_project\n",
       "44                  word_freq_re\n",
       "45                 word_freq_edu\n",
       "46               word_freq_table\n",
       "47          word_freq_conference\n",
       "48                   char_freq_;\n",
       "49                   char_freq_(\n",
       "50                   char_freq_[\n",
       "51                   char_freq_!\n",
       "52                   char_freq_$\n",
       "53                   char_freq_#\n",
       "54    capital_run_length_average\n",
       "55    capital_run_length_longest\n",
       "56      capital_run_length_total\n",
       "57                          spam\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# en el archivo spambase.data viene la data de las 56 columnas\n",
    "df = pd.read_csv('spambase.data', names=df_names[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0            0.00               0.64           0.64           0.0   \n",
       "1            0.21               0.28           0.50           0.0   \n",
       "\n",
       "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0           0.32            0.00              0.00                0.00   \n",
       "1           0.14            0.28              0.21                0.07   \n",
       "\n",
       "   word_freq_order  word_freq_mail  ...  char_freq_;  char_freq_(  \\\n",
       "0              0.0            0.00  ...          0.0        0.000   \n",
       "1              0.0            0.94  ...          0.0        0.132   \n",
       "\n",
       "   char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n",
       "0          0.0        0.778         0.00        0.000   \n",
       "1          0.0        0.372         0.18        0.048   \n",
       "\n",
       "   capital_run_length_average  capital_run_length_longest  \\\n",
       "0                       3.756                          61   \n",
       "1                       5.114                         101   \n",
       "\n",
       "   capital_run_length_total  spam  \n",
       "0                       278     1  \n",
       "1                      1028     1  \n",
       "\n",
       "[2 rows x 58 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verifique los primeros registros del dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# imprima las dimensiones del dataframe\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpieza de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verifique la estructura del set de datos\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verifique si tiene valore nulos, de ser así, haga un tratamiento de ellos\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definición del modelo\n",
    "\n",
    "Defina un modelo con todas los features. Note que la última columna (spam) contiene la variable objetivo (es spam o no es spam)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todas las columnas excepto 'spam' serán features\n",
    "X = df.drop('spam', axis=1)\n",
    "\n",
    "// La columna 'spam' es la variable objetivo (0 = no spam, 1 = spam)\n",
    "y = df['spam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# verifique los valores únicos de la variable objetivo\n",
    "print(\"Conteo de clases:\")\n",
    "print(y.value_counts())\n",
    "print(\"\\nProporción de clases:\")\n",
    "print(y.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escalamiento de los datos\n",
    "\n",
    "No, generalmente no es necesario escalar los datos cuando se utiliza el clasificador bayesiano ingenuo (Naive Bayes). Esto se debe a que el Naive Bayes no hace suposiciones sobre la distribución de las características y trata cada característica de manera independiente, asumiendo que son condicionalmente independientes dado el valor de la clase objetivo.\n",
    "\n",
    "Dado que el Naive Bayes calcula las probabilidades condicionales de cada característica dada la clase objetivo, el escalado de las características no afecta directamente estas probabilidades condicionales. Por lo tanto, no se requiere escalado para el clasificador Naive Bayes.\n",
    "\n",
    "Sin embargo, existen algunas excepciones en las que el escalado de características puede ser útil, como en el caso de características que tienen escalas muy diferentes o en conjuntos de datos donde las características están altamente sesgadas. En tales casos, el escalado puede ayudar a mejorar el rendimiento del modelo.\n",
    "\n",
    "En resumen, mientras que el escalado de características puede ser beneficioso en otros algoritmos de machine learning, como los basados en distancias (por ejemplo, k-Nearest Neighbors) o en gradientes (por ejemplo, Support Vector Machines), generalmente no es necesario para el clasificador bayesiano ingenuo debido a su naturaleza y suposiciones específicas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta guía compararemos el performance del modelo bayesiano con datos sin escalar y frente a un modelo con los datos escalados. Por lo tanto, dejaremos los datos escalados en una variable distinta para su utilización posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# escalar el set de datos\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validación Cruzada (Datos sin Escalar)\n",
    "\n",
    "Realizaremos la división del set de test y de entrenamiento con los datos sin escalar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividir set de entrenamiento y test (datos sin escalar)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento Algoritmo\n",
    "\n",
    "\n",
    "El algoritmo de Naive Bayes tiene varias ventajas que lo hacen ampliamente utilizado en problemas de clasificación. Aquí están algunas de las principales ventajas:\n",
    "\n",
    "- **Simplicidad y facilidad de implementación**: Naive Bayes es un algoritmo simple y fácil de entender. Su naturaleza intuitiva y sus suposiciones simples hacen que sea fácil de implementar y comprender, lo que lo hace adecuado para aplicaciones prácticas.\n",
    "\n",
    "- **Eficiencia computacional**: Naive Bayes es computacionalmente eficiente y puede manejar grandes volúmenes de datos de manera efectiva. Los tiempos de entrenamiento y predicción suelen ser rápidos, lo que lo hace adecuado para aplicaciones en tiempo real o con grandes conjuntos de datos.\n",
    "\n",
    "- **Bajo riesgo de sobreajuste**: Debido a su simplicidad y sus suposiciones de independencia condicional, Naive Bayes tiende a tener un bajo riesgo de sobreajuste, especialmente en conjuntos de datos con muchas características. Esto lo hace robusto y generalizable a nuevos datos.\n",
    "\n",
    "- **Manejo eficaz de datos categóricos y textuales**: Naive Bayes es especialmente adecuado para problemas con características categóricas o textuales, como la clasificación de documentos de texto o la detección de spam de correo electrónico. Puede manejar estas características de manera efectiva sin necesidad de preprocesamiento complejo.\n",
    "\n",
    "- **Capacidad para modelar probabilidades**: Naive Bayes proporciona una forma natural de modelar probabilidades condicionales y de hacer predicciones basadas en estas probabilidades. Esto lo hace útil para problemas de clasificación donde se requiere una estimación de la probabilidad de pertenencia a una clase.\n",
    "\n",
    "- **Adaptabilidad a conjuntos de datos desequilibrados**: Naive Bayes puede funcionar bien incluso en conjuntos de datos desequilibrados, donde hay una gran diferencia en la cantidad de muestras por clase. Esto se debe a que el algoritmo se basa en la probabilidad y no en la distribución de las muestras.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar algoritmo bayesiano\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustar modelo Naive Bayes con datos sin escalar\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy simple en entrenamiento y test\n",
    "print(f\"Accuracy en entrenamiento: {model.score(X_train, y_train):.3f}\")\n",
    "print(f\"Accuracy en test        : {model.score(X_test, y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas de Evaluación\n",
    "\n",
    "Al evaluar las métricas de clasificación de un algoritmo de detección de spam, es importante tener en cuenta varios aspectos para asegurar una evaluación precisa y significativa del rendimiento del modelo. Algunos de los cuidados que debemos tener incluyen:\n",
    "\n",
    "- **Desbalance de clases**: En problemas de detección de spam, es común que las clases estén desbalanceadas, es decir, que haya muchas más instancias de correos legítimos que de spam. Esto puede sesgar las métricas de evaluación, especialmente si el algoritmo predice la clase dominante en la mayoría de los casos. Es importante considerar métricas que sean robustas frente al desbalance de clases, como precision, recall y F1-score.\n",
    "\n",
    "- **Evaluación en datos no vistos**: Es fundamental evaluar el rendimiento del modelo en un conjunto de datos no vistos o conjunto de prueba independiente (set de test). Esto garantiza que el modelo sea capaz de generalizar a nuevos correos electrónicos y no solo memorice los datos de entrenamiento.\n",
    "\n",
    "- **Métricas apropiadas**: Las métricas de evaluación deben seleccionarse cuidadosamente según las necesidades y objetivos del problema. Por ejemplo, precision y recall son útiles para evaluar el equilibrio entre la capacidad de identificar spam (recall) y la precisión de estas predicciones (precision).\n",
    "\n",
    "- **Considerar costos asociados**: Dependiendo del contexto, los costos asociados con los errores de clasificación pueden variar. Por ejemplo, el costo de clasificar incorrectamente un correo legítimo como spam puede ser diferente del costo de clasificar incorrectamente un correo de spam como legítimo. Es importante tener en cuenta estos costos al interpretar las métricas de evaluación y al tomar decisiones sobre la configuración del modelo.\n",
    "\n",
    "- **Interpretación de las métricas**: Es esencial comprender el significado de las métricas de evaluación y cómo se relacionan con el problema específico de detección de spam. Por ejemplo, un alto recall indica que el modelo es capaz de detectar la mayoría de los correos de spam, mientras que un alto precision indica que las predicciones positivas del modelo son en su mayoría correctas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar librerias de métricas\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# realizar predicciones sobre el X_test (datos sin escalar)\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular métricas de evaluación para datos sin escalar\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f\"Accuracy : {acc:.3f}\")\n",
    "print(f\"Precision: {prec:.3f}\")\n",
    "print(f\"Recall   : {rec:.3f}\")\n",
    "print(f\"F1-score : {f1:.3f}\")\n",
    "print(\"\\nReporte de clasificación (Naive Bayes sin escalar):\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de confusión para modelo Naive Bayes (sin escalar)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title('Matriz de confusión - Naive Bayes (sin escalar)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Tabla de contingencia Real vs Predicción (sin escalar)\n",
    "pd.crosstab(y_test, y_pred, rownames=['Real'], colnames=['Predicción'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparación con Datos Escalados\n",
    "\n",
    "En esta sección, realizaremos el entrenamiento con los datos escalados para ver si hay diferencias en el performance del modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validación cruzada con datos escalados\n",
    "X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(\n",
    "    X_scaled, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "X_train_s.shape, X_test_s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Entrenamiento con datos escalados\n",
    "model_scaled = GaussianNB()\n",
    "model_scaled.fit(X_train_s, y_train_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Métricas de evaluación con datos escalados\n",
    "y_pred_s = model_scaled.predict(X_test_s)\n",
    "acc_s = accuracy_score(y_test_s, y_pred_s)\n",
    "prec_s = precision_score(y_test_s, y_pred_s)\n",
    "rec_s = recall_score(y_test_s, y_pred_s)\n",
    "f1_s = f1_score(y_test_s, y_pred_s)\n",
    "print(f\"Accuracy (scaled) : {acc_s:.3f}\")\n",
    "print(f\"Precision (scaled): {prec_s:.3f}\")\n",
    "print(f\"Recall (scaled)   : {rec_s:.3f}\")\n",
    "print(f\"F1-score (scaled) : {f1_s:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusiones y Reflexiones\n",
    "\n",
    "Por ultimo realizaremos un entrenamiento del modelo con el valor de K determinado anteriormente. Algunas preguntas que pueden ayudar a reflexionar:\n",
    "\n",
    "- En este problema, ¿mejora el performance respecto a otros algoritmos utilizadas previamente? \n",
    "- En este caso, ¿se produce una mejora con el escalamiento?\n",
    "- ¿Cuándo sería recomendable utilizar este tipo de algoritmo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conclusiones aquí\n",
    "\"\"\"\n",
    "- Resume las diferencias de desempeño entre Naive Bayes sin escalar y con datos escalados.\n",
    "- Comenta si el escalamiento ayudó o no al modelo bayesiano en este caso.\n",
    "- Compara (si lo recuerdas) con otros modelos vistos (por ejemplo KNN, Regresión Logística),\n",
    "  pensando en ventajas/desventajas de Naive Bayes para el problema de spam.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si llegaste hasta acá Eres un crack!\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
