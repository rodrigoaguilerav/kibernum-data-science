{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Guía Redes Neuronales Densas\n",
    "\n",
    "En esta guía abordaremos los siguientes tópicos:\n",
    "- Preparación de datos y codificación One-Hot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparación de datos y codificación One-Hot\n",
    "\n",
    "A menudo, se recomienda realizar preparaciones de los datos de formas específicas antes de ajustar un modelo de machine learning. ¿Por qué? porque algunos algoritmos no pueden trabajar con datos categóricos directamente. Por ejemplo, un arbol de decisión puede aprender directamente de la data categórica sin necesidad de transformación de data (aunque esto podría depender de la implementación). Sin embargo, existen varios algoritmos que no pueden operar directamente con los datos categóricos y que requieren que, tanto las variables de entrada como las de salida, sean numéricas.\n",
    "\n",
    "**¿Cómo convertir data categórica en data numérica?**\n",
    "\n",
    "Esto conlleva dos etapas:\n",
    "- Codificación entera\n",
    "- Codificación One-Hot\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Codificación Entera**\n",
    "\n",
    "Consiste en asignar un valor enterno a cada categoría. Los valores enteros tienen una relación ordenada de cada valor, lo cual puede ser útil para que los algoritmos de machine learning puedan entender la relación entre categorías. Por ejemplo, variables ordinales tales como \"grado de satisfacción\" podría ser suficiente utilizar una codificación entera. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de una codificación entera\n",
    "satisfaccion = ['malo','mas o menos','bueno','bueno','malo','bueno','malo','mas o menos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores con condificacion entera: [1 2 0 0 1 0 1 2]\n",
      "Clases: ['bueno' 'malo' 'mas o menos']\n"
     ]
    }
   ],
   "source": [
    "# Label Encoding\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(satisfaccion)\n",
    "label_encoded = label_encoder.transform(satisfaccion)\n",
    "\n",
    "print(\"Valores con condificacion entera:\",label_encoded)\n",
    "print(\"Clases:\", label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El atributo `classes_` contiene una lista de las clases únicas encontradas en los datos de entrenamiento, ordenadas alfabéticamente o por orden de aparición en los datos, dependiendo de la implementación específica de LabelEncoder. Estos son los valores que el LabelEncoder ha asignado a las clases después de ajustarse a los datos. Puedes utilizar estos valores para entender cómo han sido codificadas las clases. En este caso, no se cumple el propósito de darle un ordenamiento lógico a los niveles de satisfacción, pero esto se puede arreglar de la siguiente forma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores con condificacion entera: [0 1 2 2 0 2 0 1]\n",
      "Clases: ['malo' 'mas o menos' 'bueno']\n"
     ]
    }
   ],
   "source": [
    "# Definir el mapeo entre las clases y los valores asignados\n",
    "mapeo_clases = {'malo': 0, 'mas o menos': 1, 'bueno': 2}\n",
    "\n",
    "# Aplicar el mapeo al LabelEncoder\n",
    "label_encoder.classes_ = np.array([k for k, v in sorted(mapeo_clases.items(), key=lambda item: item[1])])\n",
    "\n",
    "# ajustamos nuevamente el encoder\n",
    "label_encoded = label_encoder.transform(satisfaccion)\n",
    "\n",
    "\n",
    "print(\"Valores con condificacion entera:\",label_encoded)\n",
    "print(\"Clases:\", label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Codificación One-Hot**\n",
    "\n",
    "La codificación One-Hot (también conocida como one-of-K encoding o dummy encoding) es una técnica utilizada en el procesamiento de datos para convertir variables categóricas en una forma que puede ser proporcionada a algoritmos de aprendizaje automático para mejorar su rendimiento.\n",
    "\n",
    "En la codificación One-Hot, cada categoría única en la variable categórica se convierte en una nueva característica binaria (o \"dummy\"), donde cada característica representa una categoría distinta y tiene un valor de 1 si la observación pertenece a esa categoría y 0 en caso contrario. De esta manera, se crea una matriz de características binarias donde cada fila representa una observación y cada columna representa una categoría.\n",
    "\n",
    "Por ejemplo, supongamos que tienes una variable categórica \"Color\" con tres categorías: \"Rojo\", \"Verde\" y \"Azul\". La codificación One-Hot convertiría esta variable en tres nuevas características binarias:\n",
    "\n",
    "- \"Rojo\": [1, 0, 0]\n",
    "- \"Verde\": [0, 1, 0]\n",
    "- \"Azul\": [0, 0, 1]\n",
    "\n",
    "Estas características se utilizan luego como entradas para entrenar un modelo de aprendizaje automático. La codificación One-Hot es útil porque permite que los algoritmos de aprendizaje automático trabajen con variables categóricas sin asumir ningún orden o relación entre las categorías, lo que puede ser importante en muchas aplicaciones.\n",
    "\n",
    "En Python, puedes realizar la codificación One-Hot utilizando funciones de bibliotecas como scikit-learn o pandas. Por ejemplo, en scikit-learn, puedes utilizar la clase OneHotEncoder, mientras que en pandas, puedes usar la función get_dummies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de características categóricas\n",
    "colores = [['Rojo'], ['Verde'], ['Azul'], ['Rojo'], ['Verde']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Características codificadas:\n",
      "[[0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n",
      "Dimensiones arreglo codificado: (5, 3)\n",
      "Categirías: [array(['Azul', 'Rojo', 'Verde'], dtype=object)]\n"
     ]
    }
   ],
   "source": [
    "# Inicializar y ajustar el OneHotEncoder\n",
    "encoder = OneHotEncoder()\n",
    "encoder.fit(colores)\n",
    "\n",
    "# Transformar las características utilizando el OneHotEncoder\n",
    "categorias_codificadas = encoder.transform(colores)\n",
    "\n",
    "# Convertir las características codificadas a un array NumPy\n",
    "categorias_codificadas_array = categorias_codificadas.toarray()\n",
    "\n",
    "print(\"Características codificadas:\")\n",
    "print(categorias_codificadas_array)\n",
    "\n",
    "print(\"Dimensiones arreglo codificado:\", categorias_codificadas_array.shape)\n",
    "\n",
    "print(\"Categirías:\", encoder.categories_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora resolveremos el problema de la flor iris, realizando una codificación one hot de la variable objetivo (species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                5.1               3.5                1.4               0.2\n",
       "1                4.9               3.0                1.4               0.2\n",
       "2                4.7               3.2                1.3               0.2\n",
       "3                4.6               3.1                1.5               0.2\n",
       "4                5.0               3.6                1.4               0.2"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bunch = load_iris()\n",
    "df = pd.DataFrame(bunch.data, columns=bunch.feature_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df\n",
    "y = bunch.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocesamiento de los datos**\n",
    "\n",
    "En este caso, realice los siguientes preprocesamientos:\n",
    "\n",
    "- Escalamiento de los datos\n",
    "- Codificación one-hot para la variable objetivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "# Escalamiento de las variables de entrada\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Codificación one-hot de la variable objetivo\n",
    "y_reshaped = y.reshape(-1, 1)\n",
    "ohe = OneHotEncoder(sparse_output=False)\n",
    "y_onehot = ohe.fit_transform(y_reshaped)\n",
    "\n",
    "print(\"Shape X_scaled:\", X_scaled.shape)\n",
    "print(\"Shape y_onehot:\", y_onehot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar primeras filas de la codificación one-hot\n",
    "y_onehot[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Validación cruzada**\n",
    "\n",
    "Divida el set de datos en traun y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y_onehot,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"X_test :\", X_test.shape)\n",
    "print(\"y_train:\", y_train.shape)\n",
    "print(\"y_test :\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Diseño Arquitectura**\n",
    "\n",
    "Ahora diseñe una arquitectura para la red neuronal similar a la utilizada en la actividad anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "n_classes = y_train.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(4, activation='tanh', input_shape=(input_dim,)))\n",
    "model.add(Dense(10, activation='tanh'))\n",
    "model.add(Dense(8, activation='tanh'))\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "optimizer = Adam(learning_rate=0.02)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=100,\n",
    "    batch_size=16,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Entrenamiento ANN**\n",
    "\n",
    "Entrene la red definida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Realizando predicciones**\n",
    "\n",
    "Realice predicciones para la siguiente medición:\n",
    "\n",
    "    [4.7,\t3.2, \t1.3, \t0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "p1 = [4.7, 3.2, 1.3, 0.2]\n",
    "\n",
    "# Escalamos el nuevo punto con el mismo scaler\n",
    "p1_arr = np.array(p1).reshape(1, -1)\n",
    "p1_scaled = scaler.transform(p1_arr)\n",
    "\n",
    "# Predicción de probabilidades y clase\n",
    "p1_proba = model.predict(p1_scaled)\n",
    "p1_class = np.argmax(p1_proba, axis=1)[0]\n",
    "p1_species = bunch.target_names[p1_class]\n",
    "\n",
    "print(\"Probabilidades:\", p1_proba)\n",
    "print(\"Clase predicha (índice):\", p1_class)\n",
    "print(\"Especie predicha:\", p1_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# realice prediccione en el set de test\n",
    "y_pred_proba = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "y_test_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Métricas de evaluación**\n",
    "\n",
    "Calcule las métricas de evaluación al modelo entrenado (score, matriz de confusión)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "cm = confusion_matrix(y_test_labels, y_pred)\n",
    "print(\"Matriz de confusión:\\n\", cm)\n",
    "\n",
    "print(\"\\nReporte de clasificación:\\n\")\n",
    "print(classification_report(y_test_labels, y_pred))\n",
    "\n",
    "acc = accuracy_score(y_test_labels, y_pred)\n",
    "print(\"\\nAccuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score del modelo en el conjunto de test\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Score en test - loss:\", test_loss)\n",
    "print(\"Score en test - accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusiones\n",
    "\n",
    "Escriba acá sus conclusiones y reflexiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conclusiones acá\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
