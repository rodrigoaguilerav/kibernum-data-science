{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93598a81",
   "metadata": {},
   "source": [
    "# Deep Learning y Frameworks con el dataset Iris\n",
    "\n",
    " redes neuronales, frameworks de Deep Learning y el proceso de entrenamiento, usando el dataset Iris"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730cf8ac",
   "metadata": {},
   "source": [
    "## 1. Arquitectura de Red Neuronal\n",
    "Las redes neuronales convolucionales (CNN) son ideales para tareas de visión por computadora porque pueden extraer automáticamente patrones espaciales de las imágenes. Sus principales capas son:\n",
    "- **Capa convolucional:** Extrae características locales usando filtros.\n",
    "- **Capa de activación (ReLU):** Introduce no linealidad.\n",
    "- **Capa de agrupamiento (Pooling):** Reduce la dimensionalidad y ayuda a generalizar.\n",
    "- **Capas densas (Fully Connected):** Integran la información para la clasificación final."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4caad8fb",
   "metadata": {},
   "source": [
    "## 2. Frameworks para Deep Learning\n",
    "- **TensorFlow:** Muy potente y escalable, ideal para producción y grandes proyectos.\n",
    "- **Keras:** Fácil de usar, modular y compatible con TensorFlow. Recomendado para prototipos y enseñanza.\n",
    "- **PyTorch:** Flexible, intuitivo y excelente para investigación y depuración.\n",
    "\n",
    "Para clasificación de imágenes, Keras es ideal por su simplicidad y compatibilidad, aunque PyTorch es preferido en investigación avanzada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2e0d1b",
   "metadata": {},
   "source": [
    "## 3. Proceso de Entrenamiento con el dataset Iris\n",
    "El dataset Iris se usará para ilustrar el proceso de entrenamiento y evaluación de un modelo de clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8003ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f4428a",
   "metadata": {},
   "source": [
    "### Entrenamiento y evaluación con Keras\n",
    "A continuación, se entrena una red neuronal densa usando Keras para clasificar las especies de Iris."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8669bc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Input(shape=(4,)), \n",
    "    keras.layers.Dense(8, activation='relu'),\n",
    "    keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "y_train_cat = keras.utils.to_categorical(y_train, 3)\n",
    "y_test_cat = keras.utils.to_categorical(y_test, 3)\n",
    "history = model.fit(X_train_scaled, y_train_cat, epochs=70, batch_size=16, validation_split=0.2, verbose=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beff30ac",
   "metadata": {},
   "source": [
    "### Hiperparametros\n",
    "\n",
    "- **epochs:** Número de veces que el modelo recorre todo el conjunto de entrenamiento. Más épocas pueden mejorar el aprendizaje, pero también aumentar el riesgo de sobreajuste.\n",
    "- **batch_size:** Cantidad de muestras procesadas antes de actualizar los pesos. Un batch pequeño puede hacer el entrenamiento más ruidoso pero rápido; uno grande es más estable pero requiere más memoria.\n",
    "- **validation_split:** Proporción del conjunto de entrenamiento reservada para validar el modelo en cada época. Ayuda a monitorear el desempeño y detectar sobreajuste.\n",
    "- **verbose:** Nivel de detalle de la salida durante el entrenamiento. `0` no muestra nada, `1` muestra una barra de progreso, `2` muestra una línea por época.\n",
    "\n",
    "Otros hiperparámetros importantes (definidos en el modelo, no en fit):\n",
    "- **optimizer:** Algoritmo para actualizar los pesos (ej. 'adam', 'sgd'). Afecta la velocidad y calidad del aprendizaje.\n",
    "- **learning_rate:** Tasa de aprendizaje del optimizador. Controla cuánto se ajustan los pesos en cada paso.\n",
    "- **número y tamaño de capas ocultas:** Determinan la capacidad de la red para aprender patrones complejos.\n",
    "- **función de activación:** Define cómo responde cada neurona (ej. 'relu', 'sigmoid', 'softmax').\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f6d4cb",
   "metadata": {},
   "source": [
    "### Evaluación del modelo\n",
    "Se evalúa el desempeño usando varias métricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9007c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001877FCD3C40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/stepWARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001877FCD3C40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Exactitud: 0.7777777777777778\n",
      "F1-score: 0.7767857142857143\n",
      "Log Loss: 0.46565983579645026\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        15\n",
      "  versicolor       0.69      0.60      0.64        15\n",
      "   virginica       0.65      0.73      0.69        15\n",
      "\n",
      "    accuracy                           0.78        45\n",
      "   macro avg       0.78      0.78      0.78        45\n",
      "weighted avg       0.78      0.78      0.78        45\n",
      "\n",
      "Matriz de confusión:\n",
      "[[15  0  0]\n",
      " [ 0  9  6]\n",
      " [ 0  4 11]]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, log_loss\n",
    "y_pred_prob = model.predict(X_test_scaled)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "print('Exactitud:', accuracy_score(y_test, y_pred))\n",
    "print('F1-score:', f1_score(y_test, y_pred, average='weighted'))\n",
    "print('Log Loss:', log_loss(y_test, y_pred_prob))\n",
    "print('Reporte de clasificación:')\n",
    "print(classification_report(y_test, y_pred, target_names=iris.target_names))\n",
    "print('Matriz de confusión:')\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cf6a2c",
   "metadata": {},
   "source": [
    "## 4. Casos de Uso de Deep Learning\n",
    "Además de clasificación de imágenes, Deep Learning se usa en traducción automática, análisis de sentimientos, reconocimiento de voz, generación de texto, sistemas de recomendación, detección de fraudes, conducción autónoma, entre otros.\n",
    "\n",
    "Machine Learning tradicional es más adecuado cuando los datos son tabulares, pequeños o el problema es simple y no requiere modelar relaciones complejas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8a1585",
   "metadata": {},
   "source": [
    "\n",
    "1. ¿Por qué una CNN es adecuada para clasificación de imágenes?\n",
    "2. ¿Qué ventajas y desventajas tienen TensorFlow, Keras y PyTorch?\n",
    "3. ¿Qué métricas usarías para evaluar el modelo?\n",
    "4. ¿En qué casos usarías Deep Learning y en cuáles Machine Learning tradicional?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37dd484",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "**1. ¿Por qué una CNN es adecuada para clasificación de imágenes?**  \n",
    "Las redes neuronales convolucionales (CNN) son ideales para imágenes porque pueden detectar automáticamente patrones espaciales, como bordes, texturas y formas, usando filtros en las capas convolucionales. Esto permite que la red aprenda representaciones jerárquicas y generalice mejor en tareas de visión por computadora.\n",
    "\n",
    "---\n",
    "\n",
    "**2. ¿Qué ventajas y desventajas tienen TensorFlow, Keras y PyTorch?**  \n",
    "- **TensorFlow:** Muy potente y escalable, ideal para producción y grandes volúmenes de datos. Puede ser más complejo de usar.\n",
    "- **Keras:** Fácil de usar, modular y compatible con TensorFlow. Perfecto para prototipos y enseñanza, pero menos flexible para investigación avanzada.\n",
    "- **PyTorch:** Muy flexible, intuitivo y excelente para depuración y experimentación. Preferido en investigación, pero menos extendido en producción empresarial.\n",
    "\n",
    "---\n",
    "\n",
    "**3. ¿Qué métricas usarías para evaluar el modelo?**  \n",
    "- **Exactitud (accuracy):** Proporción de predicciones correctas.\n",
    "- **F1-score:** Equilibrio entre precisión y recall, útil si las clases están desbalanceadas.\n",
    "- **Log Loss:** Penaliza predicciones poco seguras, útil para modelos probabilísticos.\n",
    "- **Reporte de clasificación:** Incluye precisión, recall y F1-score por clase.\n",
    "- **Matriz de confusión:** Permite ver errores específicos entre clases.\n",
    "\n",
    "---\n",
    "\n",
    "**4. ¿En qué casos usarías Deep Learning y en cuáles Machine Learning tradicional?**  \n",
    "- **Deep Learning:** Cuando los datos son grandes, complejos y tienen estructura espacial o secuencial (imágenes, audio, texto). Ejemplo: reconocimiento de imágenes, traducción automática.\n",
    "- **Machine Learning tradicional:** Cuando los datos son tabulares, pequeños o el problema es simple y no requiere modelar relaciones complejas. Ejemplo: predicción de ventas, scoring de crédito.\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
