{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Guía Perceptrón\n",
    "\n",
    "En estea guía realizaremos las siguientes actividades:\n",
    "- Repasar conceptos fundamentales del perceptrón\n",
    "- Resolver desafíos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### El Perceptrón\n",
    "\n",
    "Un perceptrón es un algoritmo de aprendizaje supervisado en el campo del aprendizaje automático y la inteligencia artificial. \n",
    "Se utiliza para la clasificación de datos y forma la base de las redes neuronales artificiales. \n",
    "Fue propuesto por Frank Rosenblatt en 1957 y se considera una de las formas más simples de una neurona artificial.\n",
    "\n",
    "En términos simples, un perceptrón toma un conjunto de entradas, realiza una combinación lineal de estas entradas multiplicadas por los pesos correspondientes, \n",
    "y luego aplica una función de activación para producir una salida. \n",
    "Esta salida puede ser binaria (0 o 1) o puede ser una salida continua, dependiendo de la función de activación utilizada.\n",
    "\n",
    "La función de activación típicamente utilizada en un perceptrón es una función escalón (step function), que devuelve 1 si la suma ponderada de las entradas es mayor \n",
    "o igual a un cierto umbral, y 0 en caso contrario. Esto significa que un perceptrón puede aprender a clasificar datos en dos categorías, \n",
    "separando los puntos en un espacio dimensional en dos regiones con una línea (o hiperplano en dimensiones superiores).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementación\n",
    "\n",
    "El siguiente código define una clase Perceptrón con métodos para la inicialización, entrenamiento y predicción de valores.\n",
    "\n",
    "En el método `__init__`, inicializamos los atributos del perceptrón. `input_size` representa el número de características (o entradas) que tiene cada instancia de datos. `learning_rate` es la tasa de aprendizaje del perceptrón, que determina cuánto se ajustan los pesos durante el entrenamiento. `epochs` es el número de iteraciones que realizaremos sobre el conjunto de datos durante el entrenamiento.\n",
    "\n",
    "\n",
    "El método `predict` toma las entradas (inputs) y calcula la suma ponderada de las entradas multiplicadas por los pesos, más un término de sesgo (`self.weights[0]`). Luego, aplica una función de activación, que en este caso es una función escalón, y devuelve la salida (0 o 1).\n",
    "\n",
    "El método `train` realiza el entrenamiento del perceptrón. Itera sobre el conjunto de datos `epochs` veces. En cada iteración, itera sobre cada ejemplo de entrenamiento `(inputs, label)` en `training_inputs` y `labels`. Para cada ejemplo, realiza una predicción utilizando el método `activation`. Luego, ajusta los pesos del perceptrón según el error entre la predicción y la etiqueta verdadera, multiplicado por la tasa de aprendizaje y las entradas. Esto se hace utilizando la regla de aprendizaje del perceptrón."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, input_size, learning_rate=0.01, epochs=100):\n",
    "        self.weights = np.zeros(input_size + 1)\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "\n",
    "    def train(self, training_inputs, labels):\n",
    "        for _ in range(self.epochs):\n",
    "            for inputs, label in zip(training_inputs, labels):\n",
    "                prediction = self.activation(inputs)\n",
    "                self.weights[1:] += self.learning_rate * (label - prediction) * inputs\n",
    "                self.weights[0] += self.learning_rate * (label - prediction)\n",
    "\n",
    "    def activation(self, input):\n",
    "        summation = np.dot(input, self.weights[1:]) + self.weights[0]\n",
    "        return 1 if summation > 0 else 0\n",
    "\n",
    "    def predict(self, input_array):\n",
    "        return np.array([self.activation(x) for x in input_array])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay que recalcar que esta implementación está hecha para resolver problemas de **clasificación binaria**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Carga del set de datos**\n",
    "\n",
    "Ahora utilizaremos el set de datos de notas de estudiantes versus horas de estudio. Recuerde que la nota de aprobación es 55, por lo tanto, debe agregar una columna nueva con valor 0 si no aprueba, y con valor 1 si aprueba. Esa columna correspondería a la variable objetivo con la cual vamos a etiquetar los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('student_scores.csv')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# haga el wrangling para agregar la variable objetivo al set de datos\n",
    "df['aprueba'] = (df['Scores'] >= 55).astype(int)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definición del modelo**\n",
    "\n",
    "Defina la matriz de features `X` y el vector de etiquetas `y`. Recuerde que estas variables deben ser arreglos numpy para que la clase `Perceptron` pueda tratarlos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# en este caso, trabajaremos con arreglos numpy, por eso utilizamos .value\n",
    "X = df[['Hours']].values\n",
    "y = df['aprueba'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Validación cruzada**\n",
    "\n",
    "Divida el set de entrenamiento en training y test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar funcion para division de datos\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divida el set de entrenamiento\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Entrenamiento del Perceptrón**\n",
    "\n",
    "Realice el entrenamiento del perceptrón con valores por defecto para learning rate y epochs. Note que en este caso, la matriz de features tiene solamente una entrada, por lo cual `input_size` tiene valor 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear y entrenar el perceptrón\n",
    "perceptron = Perceptron(input_size=1)\n",
    "perceptron.train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# con el modelo recién ajustado, haga una predicción para un estudiante que dedica 5 horas de estudio\n",
    "# ¿aprueba la asignatura?\n",
    "perceptron.predict([[5]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluación**\n",
    "\n",
    "Aplique las métricas de evaluación al modelo entrenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred  = perceptron.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matriz de confusión\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede observar, hubo un alto accuracy en este modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptrón Titanic\n",
    "\n",
    "Ahora veremos si podemos aplicar este perceptrón para resolver el problema del Titanic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('titanic.csv')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Limpieza de datos**\n",
    "\n",
    "Para simpliplicar la operatoria, simplemente eliminaremos los registros que tienen valores nulos en las columnas en donde realizaremos el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# realizar tratamiento de valores nulos\n",
    "df = df.dropna(subset=['Survived', 'Pclass', 'Sex', 'Age', 'Fare', 'Embarked'])\n",
    "df = df.reset_index(drop=True)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definir el modelo**\n",
    "\n",
    "Como es habitual, definimos la matriz de features X y el vector de resultados y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['Pclass', 'Sex', 'Age', 'Fare', 'Embarked']]\n",
    "y = df['Survived'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocesamiento**\n",
    "\n",
    "En este problema, debemos realizar el siguiente preprocesamiento:\n",
    "- Binarizar columnas categóricas\n",
    "- Escalar los datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binarización\n",
    "X = pd.get_dummies(X, columns=['Sex', 'Embarked'], drop_first=True)\n",
    "X.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# escalamiento\n",
    "X_scaled[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Validación cruzada**\n",
    "\n",
    "Aplique división del set de datos para entrenar y testear el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# division del set de datos (recuerde que debe hacerlo con los datos escalados y binarizados)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Entrenamiento**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear y entrenar el perceptrón (recuerde que la matriz de features tiene dimensiones diferentes que en el ejemplo anterior)\n",
    "perceptron_titanic = Perceptron(input_size=X_train.shape[1], learning_rate=0.01, epochs=1000)\n",
    "perceptron_titanic.train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluación del modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicciones sobre el set de test\n",
    "y_pred_titanic = perceptron_titanic.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy\n",
    "accuracy_titanic = accuracy_score(y_test, y_pred_titanic)\n",
    "accuracy_titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matriz de confusion\n",
    "cm_titanic = confusion_matrix(y_test, y_pred_titanic)\n",
    "cm_titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Afinamiento del algoritmo**\n",
    "\n",
    "Realice una optimización de los hiperparámetros del algoritmo. Pruebe con varias combinaciones de learning_rate y epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# búsqueda simple de hiperparámetros para el perceptrón del Titanic\n",
    "learning_rates = [0.001, 0.01, 0.05, 0.1]\n",
    "epoch_list = [100, 500, 1000, 2000]\n",
    "\n",
    "results = []\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for n_epochs in epoch_list:\n",
    "        model = Perceptron(input_size=X_train.shape[1], learning_rate=lr, epochs=n_epochs)\n",
    "        model.train(X_train, y_train)\n",
    "        y_pred_grid = model.predict(X_test)\n",
    "        acc = accuracy_score(y_test, y_pred_grid)\n",
    "        results.append({'learning_rate': lr, 'epochs': n_epochs, 'accuracy': acc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizar resultados de la búsqueda de hiperparámetros\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.sort_values(by='accuracy', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mejor combinación de hiperparámetros encontrada\n",
    "best = max(results, key=lambda x: x['accuracy'])\n",
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusiones\n",
    "\n",
    "¿Qué conclusiones puede elaborar después de esta experiencia?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conclusiones acá\n",
    "conclusiones = \"\"\"\\\n",
    "En este ejercicio observamos que:\n",
    "- El perceptrón funciona bien para problemas de clasificación binaria linealmente separables.\n",
    "- En el caso de student_scores, la relación horas de estudio / aprobación es casi lineal y el modelo logra alta exactitud.\n",
    "- En Titanic, el problema es más complejo y depende de varias variables; el perceptrón puro puede tener un desempeño limitado frente a modelos más sofisticados.\n",
    "- El preprocesamiento (binarización y escalamiento) es clave para obtener buenos resultados.\n",
    "- El ajuste de hiperparámetros (learning_rate y epochs) puede mejorar el desempeño, pero con rendimientos decrecientes.\n",
    "\"\"\"\n",
    "print(conclusiones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
