{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ab182e93",
      "metadata": {
        "id": "ab182e93"
      },
      "source": [
        "## 1. Inicializar Spark y crear el contexto\n",
        "\n",
        "En esta sección:\n",
        "- Importamos las librerías necesarias.\n",
        "- Creamos una `SparkSession`.\n",
        "- Obtenemos el `SparkContext` para trabajar con RDD."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c7502b81",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7502b81",
        "outputId": "a9a42dff-f35d-4699-b57d-e78ba63d6af3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Versión de Spark: 4.0.2\n"
          ]
        }
      ],
      "source": [
        "# 1. Importar librerías y crear SparkSession\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "import os, sys\n",
        "\n",
        "os.environ[\"PYSPARK_PYTHON\"] = sys.executable\n",
        "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = sys.executable\n",
        "\n",
        "# Creamos/obtenemos una sesión de Spark\n",
        "# spark = SparkSession.builder \\\n",
        "#     .appName(\"AnalisisDiscursoPresidencial\") \\\n",
        "#     .getOrCreate()\n",
        "\n",
        "spark = (\n",
        "    SparkSession.builder\n",
        "    .appName(\"AnalisisDiscursoPresidencial\")\n",
        "    .config(\"spark.pyspark.python\", sys.executable)\n",
        "    .config(\"spark.pyspark.driver.python\", sys.executable)\n",
        "    .getOrCreate()\n",
        ")\n",
        "\n",
        "# Obtenemos el SparkContext para trabajar con RDD\n",
        "sc = spark.sparkContext\n",
        "\n",
        "print(\"Versión de Spark:\", spark.version)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37eb0aa7",
      "metadata": {
        "id": "37eb0aa7"
      },
      "source": [
        "## 2. Cargar el archivo de texto como RDD\n",
        "\n",
        "En esta sección:\n",
        "- Definimos la ruta del archivo `05 - discurso.txt`.\n",
        "- Cargamos el archivo usando `sc.textFile`.\n",
        "- Vemos algunas líneas para verificar la lectura."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2df1386b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2df1386b",
        "outputId": "8b463408-9a0d-4305-8bf0-79b3782610c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Número aproximado de líneas: 19\n",
            "\n",
            "Primeras líneas del discurso:\n",
            "\n",
            "Queridos compatriotas chilenos,\n",
            "\n",
            "Hoy me dirijo a ustedes con un corazón lleno de esperanza y determinación, consciente de los desafíos que enfrentamos como nación, pero también confiada en nuestra capacidad para superarlos juntos.\n",
            "\n",
            "En estos tiempos de incertidumbre y cambios rápidos, es crucial que permanezcamos unidos como pueblo. La unidad es nuestra mayor fortaleza y nuestra mejor defensa contra las adversidades que puedan surgir en nuestro camino.\n"
          ]
        }
      ],
      "source": [
        "# 2. Cargar el archivo de discurso como RDD\n",
        "\n",
        "# Ruta del archivo de texto.\n",
        "# Si el notebook está en la misma carpeta que el archivo (M8/S2),\n",
        "# esta ruta relativa debería funcionar directamente.\n",
        "file_path = \"/content/05 - discurso.txt\"\n",
        "\n",
        "# Cargamos el archivo como un RDD de líneas\n",
        "lines_rdd = sc.textFile(file_path)\n",
        "\n",
        "\n",
        "# Mostramos algunas líneas para verificar el contenido\n",
        "print(\"Número aproximado de líneas:\", lines_rdd.count())\n",
        "print(\"\\nPrimeras líneas del discurso:\\n\")\n",
        "for line in lines_rdd.take(5):\n",
        "    print(line)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "faa492e6",
      "metadata": {
        "id": "faa492e6"
      },
      "source": [
        "## 3. Limpieza de texto y definición de stopwords\n",
        "\n",
        "En esta sección:\n",
        "- Pasamos el texto a minúsculas.\n",
        "- Eliminamos signos de puntuación y caracteres no alfabéticos.\n",
        "- Separamos el texto en palabras.\n",
        "- Definimos una lista de **stopwords** (palabras sin mucho significado para el análisis: artículos, pronombres, etc.)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "f74eaaef",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f74eaaef",
        "outputId": "2eb33d39-c387-44ef-8e05-e0b69ec4db66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Línea original: ¡Queridos compatriotas chilenos! Hoy me dirijo a ustedes...\n",
            "Palabras limpias: ['queridos', 'compatriotas', 'chilenos', 'hoy', 'me', 'dirijo', 'a', 'ustedes']\n"
          ]
        }
      ],
      "source": [
        "# 3. Funciones de limpieza y lista de stopwords\n",
        "\n",
        "import re\n",
        "\n",
        "# Lista de palabras vacías (stopwords) en español.\n",
        "# Se puede ampliar según necesidad.\n",
        "stopwords = {\n",
        "    \"a\", \"e\", \"i\", \"o\", \"u\",\n",
        "    \"el\", \"la\", \"los\", \"las\", \"un\", \"una\", \"unos\", \"unas\",\n",
        "    \"y\", \"o\", \"u\", \"de\", \"del\", \"al\", \"en\", \"con\", \"por\", \"para\",\n",
        "    \"como\", \"que\", \"se\", \"su\", \"sus\", \"es\", \"son\", \"ser\", \"fue\", \"fueron\",\n",
        "    \"este\", \"esta\", \"estos\", \"estas\", \"ese\", \"esa\", \"esos\", \"esas\",\n",
        "    \"yo\", \"tú\", \"tu\", \"usted\", \"ustedes\", \"nosotros\", \"nosotras\",\n",
        "    \"ellos\", \"ellas\",\n",
        "    \"mi\", \"mis\", \"nuestro\", \"nuestra\", \"nuestros\", \"nuestras\",\n",
        "    \"su\", \"sus\",\n",
        "    \"un\", \"una\", \"al\", \"del\",\n",
        "    \"pero\", \"también\", \"ya\", \"muy\", \"más\", \"menos\",\n",
        "    \"que\", \"porque\", \"cuando\", \"donde\",\n",
        "    \"hoy\", \"ayer\", \"mañana\",\n",
        "    \"es\", \"son\", \"era\", \"eran\", \"ser\", \"estar\", \"está\", \"están\"\n",
        "}\n",
        "\n",
        "def limpiar_y_dividir(linea):\n",
        "    \"\"\"Convierte la línea a minúsculas, elimina puntuación y la separa en palabras.\"\"\"\n",
        "    # Pasamos a minúsculas\n",
        "    linea = linea.lower()\n",
        "    # Reemplazamos cualquier caracter que no sea letra (incluye tildes y ñ) por un espacio\n",
        "    # Conservamos letras a-z, áéíóúñü\n",
        "    linea = re.sub(r\"[^a-záéíóúñü]+\", \" \", linea)\n",
        "    # Dividimos en palabras por espacios\n",
        "    palabras = linea.split()\n",
        "    return palabras\n",
        "\n",
        "# Probamos la función de limpieza con una línea de ejemplo\n",
        "ejemplo = \"¡Queridos compatriotas chilenos! Hoy me dirijo a ustedes...\"\n",
        "print(\"Línea original:\", ejemplo)\n",
        "print(\"Palabras limpias:\", limpiar_y_dividir(ejemplo))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "022c8c94",
      "metadata": {
        "id": "022c8c94"
      },
      "source": [
        "## 4. Pipeline con RDD: contar palabras\n",
        "\n",
        "Pasos con RDD:\n",
        "1. `flatMap` para transformar líneas en palabras.\n",
        "2. `filter` para eliminar palabras vacías (stopwords) y cadenas vacías.\n",
        "3. `map` para transformar cada palabra en un par `(palabra, 1)`.\n",
        "4. `reduceByKey` para sumar las ocurrencias por palabra.\n",
        "5. `sortBy` para ordenar por frecuencia de mayor a menor.\n",
        "6. `take(10)` para obtener las **10 palabras más frecuentes**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "7885b8e9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7885b8e9",
        "outputId": "bc4993cb-dd5c-40e0-c0b2-b99005855cbf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('nos', 3),\n",
              " ('juntos', 3),\n",
              " ('me', 2),\n",
              " ('enfrentamos', 2),\n",
              " ('tiempos', 2),\n",
              " ('mejor', 2),\n",
              " ('presidenta', 2),\n",
              " ('compromiso', 2),\n",
              " ('cada', 2),\n",
              " ('construir', 2)]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 4. Construir el pipeline RDD para conteo de palabras\n",
        "\n",
        "# 4.1. Pasar de líneas a palabras limpias usando flatMap\n",
        "palabras_rdd = lines_rdd.flatMap(limpiar_y_dividir)\n",
        "\n",
        "# 4.2. Filtrar stopwords y palabras vacías\n",
        "palabras_filtradas_rdd = palabras_rdd.filter(\n",
        "    lambda w: w and (w not in stopwords)\n",
        ")\n",
        "\n",
        "# 4.3. Mapear cada palabra a un par (palabra, 1)\n",
        "pares_rdd = palabras_filtradas_rdd.map(lambda w: (w, 1))\n",
        "\n",
        "# 4.4. Reducir por clave (palabra) sumando las ocurrencias\n",
        "conteo_rdd = pares_rdd.reduceByKey(lambda a, b: a + b)\n",
        "\n",
        "# 4.5. Ordenar por frecuencia (valor) de mayor a menor\n",
        "conteo_ordenado_rdd = conteo_rdd.sortBy(lambda par: par[1], ascending=False)\n",
        "\n",
        "# 4.6. Tomar las 10 palabras más frecuentes (acción RDD)\n",
        "top_10_palabras = conteo_ordenado_rdd.take(10)\n",
        "\n",
        "top_10_palabras"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afe15285",
      "metadata": {
        "id": "afe15285"
      },
      "source": [
        "## 5. Mostrar los 10 principales términos formateados\n",
        "\n",
        "En esta sección simplemente mostramos los resultados de forma más amigable: palabra y cantidad de apariciones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "728e675c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "728e675c",
        "outputId": "62efb480-8f8f-4ef0-8121-fec849ef81da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 10 palabras más frecuentes (sin stopwords):\n",
            "\n",
            "nos             -> 3\n",
            "juntos          -> 3\n",
            "me              -> 2\n",
            "enfrentamos     -> 2\n",
            "tiempos         -> 2\n",
            "mejor           -> 2\n",
            "presidenta      -> 2\n",
            "compromiso      -> 2\n",
            "cada            -> 2\n",
            "construir       -> 2\n"
          ]
        }
      ],
      "source": [
        "# 5. Imprimir los 10 términos más frecuentes de forma legible\n",
        "\n",
        "print(\"Top 10 palabras más frecuentes (sin stopwords):\\n\")\n",
        "for palabra, frecuencia in top_10_palabras:\n",
        "    print(f\"{palabra:15s} -> {frecuencia}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff98dd1f",
      "metadata": {
        "id": "ff98dd1f"
      },
      "source": [
        "## 6. Cierre de la sesión de Spark\n",
        "\n",
        "Al finalizar el análisis, es buena práctica detener la sesión de Spark."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "15871348",
      "metadata": {
        "id": "15871348"
      },
      "outputs": [],
      "source": [
        "# 6. Detener la sesión de Spark\n",
        "\n",
        "spark.stop()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
